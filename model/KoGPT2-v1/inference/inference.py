import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

class KoGPT2Generator:
    def __init__(self, model_name="../output_dir", device=None):
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)

    def generate_text(self, prompt, max_length=140, temperature=0.8, top_k=50, top_p=0.95, repetition_penalty=1.2,
                      do_sample=True, num_candidates=5):
        """
        KoGPT2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ í…ìŠ¤íŠ¸ í›„ë³´ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.

        Returns:
        - ìƒì„±ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (list)
        """
        input_ids = self.tokenizer(prompt, return_tensors="pt").input_ids.to(self.device)

        # ğŸ”¹ ì—¬ëŸ¬ ê°œì˜ í›„ë³´ ìƒì„± (num_return_sequences ì‚¬ìš©)
        outputs = self.model.generate(
            input_ids,
            max_length=max_length,
            do_sample=do_sample,
            num_return_sequences=num_candidates,  # ğŸ”¹ ì—¬ëŸ¬ ê°œì˜ ì‘ë‹µ ìƒì„±
            top_k=top_k,
            top_p=top_p,
            temperature=temperature,
            repetition_penalty=repetition_penalty,
        )

        # ğŸ”¹ í›„ë³´ í…ìŠ¤íŠ¸ ì •ë¦¬
        candidates = []
        for output in outputs:
            generated_text = self.tokenizer.decode(output, skip_special_tokens=True)

            # ğŸ”¹ "."ìœ¼ë¡œ ë¬¸ì¥ ë¶„ë¦¬ í›„, ê³µë°± ì œê±°
            sentences = generated_text.split(".")
            cleaned_text = [s.strip() for s in sentences if s.strip()]

            # ğŸ”¹ ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì‚­ì œ
            if cleaned_text and len(cleaned_text[-1]) < 5:
                cleaned_text.pop()

            # ğŸ”¹ "."ì„ ë‹¤ì‹œ ë¶™ì—¬ì„œ ë¬¸ì¥ ì—°ê²°
            final_text = ". ".join(cleaned_text)

            # ğŸ”¹ ë§ˆì§€ë§‰ ë¬¸ì¥ì´ "." ì—†ì´ ëë‚˜ë©´ ì¶”ê°€
            if not final_text.endswith("."):
                final_text += "."

            candidates.append(final_text)

        return candidates  # ğŸ”¹ ì—¬ëŸ¬ ê°œì˜ ì‘ë‹µ ë°˜í™˜

# âœ… ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    generator = KoGPT2Generator()

    prompt = "ìƒí’ˆëª…: ë°”ë‹ë¼ì•„ì´ìŠ¤í¬ë¦¼\nì„¤ëª…:"
    results = generator.generate_text(prompt, num_candidates=5)

    print("ğŸ”¥ ìƒì„±ëœ í…ìŠ¤íŠ¸ í›„ë³´ë“¤:")
    for idx, text in enumerate(results, 1):
        print(f"[{idx}] {text}")
