import pandas as pd
from torch.utils.data import Dataset

class CustomDataset(Dataset):
    def __init__(self, file_path, tokenizer, max_length=256):
        """
        SOLAR Fine-tuningì„ ìœ„í•œ CustomDataset í´ë˜ìŠ¤
        Args:
            json_path (str): ë°ì´í„°ì…‹ JSON íŒŒì¼ ê²½ë¡œ
            tokenizer (AutoTokenizer): ì‚¬ìš©í•  í† í¬ë‚˜ì´ì €
            max_length (int): ìµœëŒ€ í† í° ê¸¸ì´
        """
        self.data = pd.read_csv(file_path, encoding="utf-8-sig")

        self.data["instruction"] = self.data["instruction"] = "ìƒí’ˆëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ê³ ê°ì´ ê´€ì‹¬ì„ ê°€ì§ˆ ë§Œí•œ ë§¤ë ¥ì ì¸ ì œí’ˆ ì„¤ëª…ì„ ìƒì„±í•˜ì„¸ìš”"

        self.data = self.data[["instruction", "name", "words"]].rename(columns={"name": "input", "words": "output"}).to_dict(
            "records")


        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.data)  # ë°ì´í„° ê°œìˆ˜ ë°˜í™˜

    def __getitem__(self, idx):
        example = self.data[idx]

        # ğŸ”¹ ëª¨ë¸ì´ í•™ìŠµí•  ë¬¸ì¥ í˜•ì‹ ì •ì˜
        prompt = f"### ì§ˆë¬¸: {example['instruction']}\n{example['input']}\n\n### ë‹µë³€: {example['output']}"

        # ğŸ”¹ í† í¬ë‚˜ì´ì§• (ì…ë ¥ê³¼ ì¶œë ¥ í•©ì³ì„œ ì²˜ë¦¬)
        encodings = self.tokenizer(
            prompt,
            truncation=True,
            padding="max_length",
            max_length=self.max_length,
            return_tensors="pt"
        )

        input_ids = encodings["input_ids"].squeeze()
        attention_mask = encodings["attention_mask"].squeeze()
        labels = encodings["input_ids"].clone()

        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels
        }
