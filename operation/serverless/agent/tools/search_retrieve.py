from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.schema import Document
import logging

class WebSearch:
    def __init__(self, region="ko-kr", time="d", max_results=3):
        self.wrapper = TavilySearchAPIWrapper()
        self.search = TavilySearchResults(api_wrapper=self.wrapper, max_results=max_results)

    def get_relevant_documents(self, query: str):
        """ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            logging.info(f"ğŸ” ì›¹ ê²€ìƒ‰ ì¤‘: {query}")
            results = self.search.run(query)

            # ê²°ê³¼ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜
            documents = []
            for i, result in enumerate(results):
                doc = Document(
                    page_content=result.get("content", "")[:500] + "...",  # ê¸¸ì´ ì œí•œ
                    metadata={
                        "source": result.get("url", ""),
                        "title": result.get("title", "")
                    }
                )
                documents.append(doc)
                logging.info(f"ê²€ìƒ‰ê²°ê³¼ {i+1}: {result.get('title', 'No title')}")

            return documents
        except Exception as e:
            logging.info(f"âŒ ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []


# ì´ì „ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
Web_search = WebSearch
